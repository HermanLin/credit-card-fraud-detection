{
 "cells": [
  {
   "source": [
    "# Credit Card Fraud Detection Project\n",
    "*By: Herman Lin and Mahika Jain*\n",
    "---\n",
    "blah"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries to be used:\n",
    "import sklearn\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.polynomial.polynomial as poly\n",
    "%matplotlib inline\n",
    "\n",
    "# Constants used throughout\n",
    "cVals = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# Read .csv file and put data into a pandas dataframe\n",
    "df = pd.read_csv('archive.zip')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# Drop empty columns\n",
    "df1 = df.dropna('columns')\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe into a numpy array\n",
    "df2 = np.array(df1)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature Names: ['Time' 'V1' 'V2' 'V3' 'V4' 'V5' 'V6' 'V7' 'V8' 'V9' 'V10' 'V11' 'V12'\n 'V13' 'V14' 'V15' 'V16' 'V17' 'V18' 'V19' 'V20' 'V21' 'V22' 'V23' 'V24'\n 'V25' 'V26' 'V27' 'V28' 'Amount']\n"
     ]
    }
   ],
   "source": [
    "# Printing the names of all the features\n",
    "# - Note: Most feature names have been anonymized to preserve confidentiality\n",
    "features = np.array(df.columns[:30])\n",
    "print('Feature Names:', features)"
   ]
  },
  {
   "source": [
    "### Note:\n",
    "\n",
    "The credit card dataset we are using for this project is naturally unbalanced. There are significantly more examples that are classified as non-fradulent than there are fradulent. One way to help counteract this is to undersample the majority class and oversample the minority class. Thus, we will be scaling our training set to contain a ratio of 5:1 non-fradulent to fradulent as well as using a fraction of the original dataset as our training and validation sets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into class_0 and class_1 examples\n",
    "zero = []\n",
    "one = []\n",
    "num_examples = df2.shape[0]\n",
    "\n",
    "for i in range(num_examples):\n",
    "    if df2[i][30] == 0:\n",
    "        zero.append(df2[i])\n",
    "    else: \n",
    "        one.append(df2[i])\n",
    "\n",
    "class_0 = np.array(zero)\n",
    "class_1 = np.array(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Class 0: 284315\nNumber of Class 1: 492\n"
     ]
    }
   ],
   "source": [
    "# Verify shapes of class_0 and class_1\n",
    "print('Number of Class 0:', class_0.shape[0])\n",
    "print('Number of Class 1:', class_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly choose 2460 examples from the entire class_0 set\n",
    "class_0_reduced = class_0[np.random.choice(284315, 2460, replace=False),:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2952, 31)\n"
     ]
    }
   ],
   "source": [
    "# Combine samples together and randomize the samples\n",
    "reduced_data = np.concatenate((class_0_reduced, class_1))\n",
    "np.random.shuffle(reduced_data)\n",
    "print(reduced_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate columns into features and target\n",
    "X = np.array(reduced_data[:,0:30]) # all rows, first 30 columns\n",
    "y = np.array(reduced_data[:,30]) # all rows, last column"
   ]
  },
  {
   "source": [
    "# sklearn Model Implementation\n",
    "\n",
    "We have created a function for easy model testing of the data. By specifying certain parameters, we are able to run either a Logisitic Regression Model (with different regularization methods) or an SVM Model (with different kernels)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#           ====================\n",
    "#           TEST DEGREES LATER!! (for polynomial kernels)\n",
    "#           ====================\n",
    "#\n",
    "\n",
    "def sklearn_model(X_tr, y_tr, X_ts, y_ts, m_type, c, iters, penalty='none', kernel=None, hidden_layer_sizes=None, activation=None, alpha=0):\n",
    "    acc_tr_model = []\n",
    "    acc_ts_model = []\n",
    "    c_model = []\n",
    "    model = None\n",
    "\n",
    "    # create model \n",
    "    if m_type == 0:\n",
    "        model = LogisticRegression(penalty=penalty, C=c, solver='saga', max_iter=iters)\n",
    "        print('Training Logistic Regression Model...')\n",
    "    elif m_type == 1:\n",
    "        model = svm.SVC(probability=True, kernel=kernel, C=c)\n",
    "        print('Training SVM Model...')\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # find the prediction on the training and testing set\n",
    "    yhat_tr = model.predict_proba(X_tr)\n",
    "    yhat_ts = model.predict_proba(X_ts)\n",
    "\n",
    "    # calculate and add accuracy values to respective lists\n",
    "    acc_tr = model.score(X_tr, y_tr)\n",
    "    acc_tr_model.append(acc_tr)\n",
    "    print(\"Accuracy on training data = %f\" % acc_tr)\n",
    "    acc_ts = model.score(X_ts, y_ts)\n",
    "    acc_ts_model.append(acc_ts)\n",
    "    print(\"Accuracy on test data = %f\" % acc_ts)\n",
    "\n",
    "    # appending value of c for graphing purposes if needed\n",
    "    c_model.append(c)\n",
    "\n",
    "    # creating a confusion matrix for analysis\n",
    "    confuse_matrix_tr = confusion_matrix(y_tr, model.predict(X_tr))\n",
    "    class_report_tr = classification_report(y_tr, model.predict(X_tr))\n",
    "    confuse_matrix_ts = confusion_matrix(y_ts, model.predict(X_ts))\n",
    "    class_report_ts = classification_report(y_ts, model.predict(X_ts))\n",
    "\n",
    "    return (acc_tr_model, acc_ts_model, c_model), (confuse_matrix_tr, confuse_matrix_ts), (class_report_tr, class_report_ts)"
   ]
  },
  {
   "source": [
    "# sklearn Neural Network Model Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network():\n",
    "    "
   ]
  },
  {
   "source": [
    "# Logisitic Regression\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1: Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data by preprocessing\n",
    "# - The idea behind StandardScaler is that it will transform your data such that \n",
    "#   its distribution will have a mean value 0 and standard deviation of 1.\n",
    "# - Mean Subtraction: for every feature subtract the mean\n",
    "#   Normalization: make all features roughly the same size\n",
    "#       Xâ€™ = (x-mean)/std\n",
    "\n",
    "X_scale = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the reduced_data into the training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.3, random_state=133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n======================Before StandardScalar==========================\n[[ 4.68810000e+04 -1.84264628e+00  1.59061918e+00 ... -8.91202286e-01\n  -3.02532802e-01  1.79900000e+01]\n [ 1.45405000e+05 -5.13686821e-01 -3.63866420e-01 ...  9.82829020e-03\n   4.01364699e-02  1.50000000e+01]\n [ 7.95860000e+04  1.00499536e+00 -3.57895870e-01 ...  7.73105736e-02\n   1.87041617e-02  3.90500000e+01]\n ...\n [ 1.44932000e+05  1.73423535e+00 -8.39642643e-01 ...  3.64383401e-02\n  -6.77362031e-03  1.22000000e+02]\n [ 6.42510000e+04 -8.95225867e-01  1.64295678e+00 ... -1.49201063e-01\n   3.64295229e-02  1.00000000e+00]\n [ 1.31024000e+05  4.69749517e-01 -1.23755547e+00 ... -1.17857669e-01\n   1.44774181e-01  7.23210000e+02]]\n\n=======================After StandardScalar==========================\n[[-0.97669032 -0.28735855  0.36512541 ... -1.43392324 -1.04110483\n  -0.3460759 ]\n [ 1.09178882  0.06890657 -0.37523487 ... -0.03318204  0.09100576\n  -0.36068779]\n [-0.29005955  0.47603224 -0.37297322 ...  0.07172585  0.02019771\n  -0.24315739]\n ...\n [ 1.08185834  0.67152562 -0.55545917 ...  0.00818592 -0.06397578\n   0.16221256]\n [-0.61201286 -0.03337575  0.38495092 ... -0.28040891  0.07875875\n  -0.42910466]\n [ 0.78986443  0.33254447 -0.70618878 ... -0.2316825   0.43670777\n   3.10027721]]\n"
     ]
    }
   ],
   "source": [
    "print('\\n======================Before StandardScalar==========================')\n",
    "print(X)\n",
    "print('\\n=======================After StandardScalar==========================')\n",
    "print(X_scale)"
   ]
  },
  {
   "source": [
    "### Step 2: Create and run the logistic regression model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Logistic Regression Model...\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "Accuracy on training data = 0.980639\n",
      "Accuracy on test data = 0.972912\n"
     ]
    }
   ],
   "source": [
    "# Perform Logisitic Regression with no Regularization\n",
    "accs_c,confusion_matrices, class_reports = sklearn_model(X_train, y_train, X_test, y_test, 0, 100000000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write results into logreg_results.txt\n",
    "with open(\"logreg_results.txt\", 'a') as file:\n",
    "    file.write(\"\\n\\n==========================\\n\")\n",
    "    file.write(\"Accuracy on training data = {}\\n\".format(accs_c[0]))\n",
    "    file.write(\"Accuracy on testing data = {}\\n\".format(accs_c[1]))\n",
    "    file.write(\"=== Confusion Matrices ===\\n\")\n",
    "    file.write(\"Training: \\n{}\\n\".format(confusion_matrices[0]))\n",
    "    file.write(\"Testing: \\n{}\\n\".format(confusion_matrices[1]))\n",
    "    file.write(\"=== Class Reports ===\\n\")\n",
    "    file.write(\"Training: \\n{}\\n\".format(class_reports[0]))\n",
    "    file.write(\"Testing: \\n{}\\n\".format(class_reports[1]))"
   ]
  },
  {
   "source": [
    "### Step 3: Plot results from the logistic regression models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1: Run SVM with a linear kernel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training SVM Model...\n",
      "Accuracy on training data = 0.894966\n",
      "Accuracy on test data = 0.881490\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.968054\n",
      "Accuracy on test data = 0.954853\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.970958\n",
      "Accuracy on test data = 0.965011\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.979671\n",
      "Accuracy on test data = 0.970655\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.980639\n",
      "Accuracy on test data = 0.971783\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.980639\n",
      "Accuracy on test data = 0.971783\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.980639\n",
      "Accuracy on test data = 0.971783\n"
     ]
    }
   ],
   "source": [
    "svm_linear_results = []\n",
    "for c in cVals:\n",
    "    svm_linear_results.append((sklearn_model(X_train, y_train, X_test, y_test, 1, c, 0, kernel='linear')))"
   ]
  },
  {
   "source": [
    "### Step 2: Run SVM with a radial basis function kernel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "svm_rbf_results = []\n",
    "for c in cVals:\n",
    "    svm_rbf_results.append((sklearn_model(X_train, y_train, X_test, y_test, 1, c, 0, kernel='rbf')))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training SVM Model...\n",
      "Accuracy on training data = 0.834463\n",
      "Accuracy on test data = 0.830700\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.834463\n",
      "Accuracy on test data = 0.830700\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.836399\n",
      "Accuracy on test data = 0.830700\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.968054\n",
      "Accuracy on test data = 0.958239\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.981607\n",
      "Accuracy on test data = 0.968397\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.989835\n",
      "Accuracy on test data = 0.968397\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.999516\n",
      "Accuracy on test data = 0.959368\n"
     ]
    }
   ]
  },
  {
   "source": [
    "### Step 3: Run SVM with a polynomial kernel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training SVM Model...\n",
      "Accuracy on training data = 0.834463\n",
      "Accuracy on test data = 0.830700\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\futur\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.834947\n",
      "Accuracy on test data = 0.831828\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.844143\n",
      "Accuracy on test data = 0.840858\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.876089\n",
      "Accuracy on test data = 0.861174\n",
      "Training SVM Model...\n",
      "Accuracy on training data = 0.876089\n",
      "Accuracy on test data = 0.861174\n"
     ]
    }
   ],
   "source": [
    "cValsGeom = np.geomspace(0.000001, 0.001, 5)\n",
    "svm_poly_results = []\n",
    "for c in cValsGeom:\n",
    "    svm_poly_results.append((sklearn_model(X_train, y_train, X_test, y_test, 1, c, 0, kernel='poly')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Neural Networks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python374jvsc74a57bd0144fb71a79f9c612d06d7a9fcb439de36ddb2e1a62502bfc5dbf46a660d6c8ef",
   "display_name": "Python 3.7.4 32-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "144fb71a79f9c612d06d7a9fcb439de36ddb2e1a62502bfc5dbf46a660d6c8ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}