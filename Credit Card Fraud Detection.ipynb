{
 "cells": [
  {
   "source": [
    "# Credit Card Fraud Detection Project\n",
    "*By: Herman Lin and Mahika Jain*\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries to be used:\n",
    "import sklearn\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, plot_precision_recall_curve, average_precision_score, precision_recall_fscore_support\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.polynomial.polynomial as poly\n",
    "%matplotlib inline\n",
    "\n",
    "# Constants used throughout the code\n",
    "cVals = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .csv file and put data into a pandas dataframe\n",
    "df = pd.read_csv('archive.zip')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "df1 = df.dropna('columns')\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe into a numpy array\n",
    "df2 = np.array(df1)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the names of all the features\n",
    "# - Note: Most feature names have been anonymized to preserve confidentiality\n",
    "features = np.array(df.columns[:30])\n",
    "print('Feature Names:', features)"
   ]
  },
  {
   "source": [
    "### Note:\n",
    "\n",
    "The credit card dataset we are using for this project is naturally unbalanced. There are significantly more examples that are classified as non-fradulent than there are fradulent. One way to help counteract this is to undersample the majority class and oversample the minority class. Thus, we will be scaling our training set to contain a ratio of 5:1 non-fradulent to fradulent as well as using a fraction of the original dataset as our training and validation sets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into class_0 and class_1 examples\n",
    "zero = []\n",
    "one = []\n",
    "num_examples = df2.shape[0]\n",
    "\n",
    "for i in range(num_examples):\n",
    "    if df2[i][30] == 0:\n",
    "        zero.append(df2[i])\n",
    "    else: \n",
    "        one.append(df2[i])\n",
    "\n",
    "class_0 = np.array(zero)\n",
    "class_1 = np.array(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify shapes of class_0 and class_1\n",
    "print('Number of Class 0:', class_0.shape[0])\n",
    "print('Number of Class 1:', class_1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly choose 2460 examples from the entire class_0 set\n",
    "class_0_reduced = class_0[np.random.choice(284315, 2460, replace=False),:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine samples together and randomize the samples\n",
    "reduced_data = np.concatenate((class_0_reduced, class_1))\n",
    "np.random.shuffle(reduced_data)\n",
    "print(reduced_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate columns into features and target\n",
    "X = np.array(reduced_data[:,0:30]) # all rows, first 30 columns\n",
    "y = np.array(reduced_data[:,30]) # all rows, last column"
   ]
  },
  {
   "source": [
    "# sklearn Model Implementation\n",
    "\n",
    "We have created a function for easy model testing of the data. By specifying certain parameters, we are able to run either a Logisitic Regression Model (with different regularization methods) or an SVM Model (with different kernels)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_model(X_tr, y_tr, X_ts, y_ts, m_type, c, iters, penalty='none', kernel=None, hidden_layer_sizes=None, activation=None, alpha=0.0001):\n",
    "    acc_tr_model = []\n",
    "    acc_ts_model = []\n",
    "    c_model = []\n",
    "    model = None\n",
    "\n",
    "    # create model \n",
    "    if m_type == 0:\n",
    "        print('Training Logistic Regression Model...')\n",
    "        model = LogisticRegression(penalty=penalty, C=c, solver='saga', max_iter=iters)\n",
    "    elif m_type == 1:\n",
    "        print('Training SVM Model...')\n",
    "        model = svm.SVC(probability=True, kernel=kernel, C=c)\n",
    "    elif m_type == 2:\n",
    "        print('Training Neural Network...')\n",
    "        model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, alpha=alpha, max_iter=iters)\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    # yhat values\n",
    "    yhat_tr = model.predict(X_tr)\n",
    "    yhat_ts = model.predict(X_ts)\n",
    "\n",
    "    # calculate and add accuracy values to respective lists\n",
    "    acc_tr = model.score(X_tr, y_tr)\n",
    "    acc_tr_model.append(acc_tr)\n",
    "    #print(\"Accuracy on training data = %f\" % acc_tr)\n",
    "    acc_ts = model.score(X_ts, y_ts)\n",
    "    acc_ts_model.append(acc_ts)\n",
    "    #print(\"Accuracy on test data = %f\" % acc_ts)\n",
    "\n",
    "    # appending value of c for graphing purposes if needed\n",
    "    c_model.append(c)\n",
    "\n",
    "    # creating a classification report for analysis\n",
    "    class_report_tr = classification_report(y_tr, yhat_tr, output_dict=True) \n",
    "    class_report_ts = classification_report(y_ts, yhat_ts, output_dict=True)\n",
    "    \n",
    "    print(\"Model Complete!\")\n",
    "\n",
    "    return (acc_tr_model, acc_ts_model, c_model), (class_report_tr, class_report_ts), model"
   ]
  },
  {
   "source": [
    "# Data Displaying\n",
    "\n",
    "Convert the return values obtained from the sklearn_model function into readable tables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_dataframe(model_set):\n",
    "    training_acc = []\n",
    "    testing_acc = []\n",
    "    cVals = []\n",
    "    for model in model_set:\n",
    "        # grab accuracies for each model\n",
    "        training_acc.append(model[0][0][0])\n",
    "        testing_acc.append(model[0][1][0])\n",
    "        cVals.append(model[0][2][0])\n",
    "\n",
    "    # convert accuracies into dictionaries\n",
    "    tr_dict, ts_dict = {}, {}\n",
    "    i = 0\n",
    "    for acc in training_acc:\n",
    "        tr_dict[cVals[i]] = acc\n",
    "        i += 1\n",
    "    i = 0\n",
    "    for acc in testing_acc:\n",
    "        ts_dict[cVals[i]] = acc\n",
    "        i += 1\n",
    "\n",
    "    c_accs = {}\n",
    "    c_accs['Acc_tr'] = tr_dict\n",
    "    c_accs['Acc_ts'] = ts_dict\n",
    "\n",
    "    # convert accuracy dict into DataFrame\n",
    "    c_acc_df = pd.DataFrame(c_accs) \n",
    "\n",
    "    # grab only precision, recall, fscore, support from the classification_report\n",
    "    prfs_lst = []\n",
    "    for model in model_set:\n",
    "        prfs_lst.append({k: model[1][0][k] for k in ('0.0', '1.0')})\n",
    "\n",
    "    return c_acc_df, prfs_lst"
   ]
  },
  {
   "source": [
    "# Plot Displaying\n",
    "\n",
    "Create plots for the Precision-Recall curve and the Accuracy versus C Values curve for the models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plots(title, model_set, X_test, y_test, acc_c_plot=True):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.subplots_adjust(wspace=0.25)\n",
    "    fig.suptitle(title)\n",
    "    cVals = []\n",
    "\n",
    "    for model in model_set:\n",
    "        plot_precision_recall_curve(model[2], X_test, y_test, ax=ax[0], name='cVal: {}'.format(model[0][2][0]))\n",
    "        cVals.append(model[0][2][0])\n",
    "    ax[0].set_title('Precision-Recall Curve')\n",
    "    #ax[0].legend(loc='center')\n",
    "\n",
    "    if acc_c_plot:\n",
    "        train = []\n",
    "        test = []\n",
    "        for model in model_set:\n",
    "            train.append(model[0][0])\n",
    "            test.append(model[0][1])\n",
    "        ax[1].plot(cVals, train,'.r-', label='Training Accuracy')\n",
    "        ax[1].plot(cVals, test,'.b-', label='Test Accuracy')\n",
    "        ax[1].set_title('Accuracy vs C Values')\n",
    "        ax[1].set_xlabel('C Value')\n",
    "        ax[1].set_ylabel('Accuracy')\n",
    "        ax[1].set_xscale('log')\n",
    "        ax[1].legend()"
   ]
  },
  {
   "source": [
    "# Logisitic Regression\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1: Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data by preprocessing\n",
    "# - The idea behind StandardScaler is that it will transform your data such that \n",
    "#   its distribution will have a mean value 0 and standard deviation of 1.\n",
    "# - Mean Subtraction: for every feature subtract the mean\n",
    "#   Normalization: make all features roughly the same size\n",
    "#       Xâ€™ = (x-mean)/std\n",
    "\n",
    "X_scale = preprocessing.StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the reduced_data into the training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scale, y, test_size=0.3, random_state=133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n======================Before StandardScalar==========================')\n",
    "print(X)\n",
    "print('\\n=======================After StandardScalar==========================')\n",
    "print(X_scale)"
   ]
  },
  {
   "source": [
    "### Step 2: Create and run the logistic regression model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Logisitic Regression with no Regularization\n",
    "# Pass a large value of C (for example, C = 100000000) to make lambda (C = 1/lambda) nearly 0.\n",
    "logreg = [] # to appease the gods in results_to_dataframe()\n",
    "logreg.append(sklearn_model(X_train, y_train, X_test, y_test, 0, 100000000, 10000))\n",
    "\n",
    "# For logreg with regularization: \n",
    "# Pass the value of C = c. Note that C is the inverse of lambda. So, small value of C i.e. b/w 0 and 1 \n",
    "# means stronger regularization and large value means less regularization.\n",
    "\n",
    "# Perform Logistic Regression with L1 Regularization\n",
    "logreg_l1 = []\n",
    "for c in cVals:\n",
    "    logreg_l1.append((sklearn_model(X_train, y_train, X_test, y_test, 0, c, 10000, 'l1')))\n",
    "\n",
    "# Perform Logistic Regression with L2 Regularization\n",
    "logreg_l2 = []\n",
    "for c in cVals:\n",
    "    logreg_l2.append((sklearn_model(X_train, y_train, X_test, y_test, 0, c, 10000, 'l2')))\n"
   ]
  },
  {
   "source": [
    "### Step 3: Display data from the logistic regression models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"\\n========== Logistic Regression without Regularization ==========\",\n",
    "          \"\\n========== Logistic Regression with L1 Regularization ==========\",\n",
    "          \"\\n========== Logistic Regression with L2 Regularization ==========\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for model_set in (logreg, logreg_l1, logreg_l2):\n",
    "    print(titles[i])\n",
    "    c_acc, prfs_lst = results_to_dataframe(model_set)\n",
    "    display(c_acc)\n",
    "\n",
    "    cVals = [model[0][2][0] for model in model_set]\n",
    "\n",
    "    j = 0\n",
    "    for prfs in prfs_lst:\n",
    "        print(\"\\ncVal: {}\".format(cVals[j]))\n",
    "        prfs_df = pd.DataFrame(prfs)\n",
    "        display(prfs_df)\n",
    "        j += 1\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Step 4: Plot results from the logistic regression models\n",
    "\n",
    "We will be plotting the results using Precision-Recall Curves since we are dealing with a large class imbalance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Plot PR Curve for Logistic Regression without Regularization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots(\"LogReg no Regularization: PR Curve\", logreg, X_test, y_test, False)"
   ]
  },
  {
   "source": [
    "### Plot PR Curve and Acc vs C Curve for Logistic Regression with L1 Regularization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots('Logistic Regression with L1 Regularization', logreg_l1, X_test, y_test)"
   ]
  },
  {
   "source": [
    "### Plot PR Curve for Logistic Regression with L2 Regularization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots('Logistic Regression with L2 Regularization', logreg_l2, X_test, y_test)"
   ]
  },
  {
   "source": [
    "### Logistic Regression with Polynomial Feature Transformation\n",
    "\n",
    "In order to explore more options, we will see what the effect of Polynomial Feature Transformation will have on a logistic regression model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1: Perform Polynomial Feature Transformation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_d2 = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_transd2 = poly_d2.fit_transform(X_train)\n",
    "X_ts_transd2 = poly_d2.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the data has been transformed\n",
    "print(X_train.shape)\n",
    "print(X_tr_transd2.shape)"
   ]
  },
  {
   "source": [
    "### Step 2: Train the Logistic Regression models using the polynomial feature transformed data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Feature Transformation of Degree 2\n",
    "# Logistic Regression with no Regularization\n",
    "logreg_transd2 = []\n",
    "logreg_transd2.append(sklearn_model(X_tr_transd2, y_train, X_ts_transd2, y_test, 0, 10000000, 10000))\n",
    "\n",
    "# Logistic Regression with L1 Regularization\n",
    "logreg_l1_transd2 = []\n",
    "for c in cVals:\n",
    "    logreg_l1_transd2.append(sklearn_model(X_tr_transd2, y_train, X_ts_transd2, y_test, 0, c, 10000, 'l1'))\n",
    "\n",
    "# Logistic Regression with L2 Regularization\n",
    "logreg_l2_transd2 = []\n",
    "for c in cVals:\n",
    "    logreg_l2_transd2.append(sklearn_model(X_tr_transd2, y_train, X_ts_transd2, y_test, 0, c, 10000, 'l2'))"
   ]
  },
  {
   "source": [
    "### Step 3: Display data from the new Logistic Regression models with PFTransformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['\\n========== LogReg without Regularization: PFT of degree 2 ==========',\n",
    "          '\\n========== LogReg with L1 Regularization: PFT of degree 2 ==========',\n",
    "          '\\n========== LogReg with L2 Regularization: PFT of degree 2 ==========']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for model_set in (logreg_transd2, logreg_l1_transd2, logreg_l2_transd2):\n",
    "    print(titles[i])\n",
    "    c_acc, prfs_lst = results_to_dataframe(model_set)\n",
    "    display(c_acc)\n",
    "\n",
    "    cVals = [model[0][2][0] for model in model_set]\n",
    "\n",
    "    j = 0\n",
    "    for prfs in prfs_lst:\n",
    "        print(\"\\ncVal: {}\".format(cVals[j]))\n",
    "        prfs_df = pd.DataFrame(prfs)\n",
    "        display(prfs_df)\n",
    "        j += 1\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "source": [
    "### Step 4: Plot results from the new Logsitic Regression Models with PFTransformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots('LogReg without Regularization: PFT of degree 2', logreg_transd2, X_ts_transd2, y_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots('LogReg with L1 Regularization: PFT of degree 2', logreg_l1_transd2, X_ts_transd2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plots('LogReg with L2 Regularization: PFT of degree 2', logreg_l2_transd2, X_ts_transd2, y_test)"
   ]
  },
  {
   "source": [
    "# Support Vector Machines"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1: Run SVM with each kernel"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with Linear Kernel\n",
    "svm_linear_results = []\n",
    "for c in cVals:\n",
    "    svm_linear_results.append((sklearn_model(X_train, y_train, X_test, y_test, 1, c, 0, kernel='linear')))"
   ]
  },
  {
   "source": [
    "# SVM with Radial Basis Function Kernel\n",
    "svm_rbf_results = []\n",
    "for c in cVals:\n",
    "    svm_rbf_results.append((sklearn_model(X_train, y_train, X_test, y_test, 1, c, 0, kernel='rbf')))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with Polynomial Kernel\n",
    "cValsGeom = np.geomspace(0.000001, 0.001, 7)\n",
    "svm_poly_results = []\n",
    "for c in cValsGeom:\n",
    "    svm_poly_results.append((sklearn_model(X_train, y_train, X_test, y_test, 1, c, 0, kernel='poly')))"
   ]
  },
  {
   "source": [
    "### Step 2: Display data obtained from the SVMs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['\\n========== SVM with Linear Kernel ==========',\n",
    "          '\\n========== SVM with RBF Kernel ==========',\n",
    "          '\\n========== SVM with Polynomial Kernel ==========']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for model_set in (svm_linear_results, svm_rbf_results, svm_poly_results):\n",
    "    print(titles[i])\n",
    "    c_acc, prfs_lst = results_to_dataframe(model_set)\n",
    "    display(c_acc)\n",
    "\n",
    "    cVals = [model[0][2][0] for model in model_set]\n",
    "\n",
    "    j = 0\n",
    "    for prfs in prfs_lst:\n",
    "        print(\"\\ncVal: {}\".format(cVals[j]))\n",
    "        prfs_df = pd.DataFrame(prfs)\n",
    "        display(prfs_df)\n",
    "        j += 1\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "source": [
    "### Step 3: Plot the results obtained from the SVM models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear kernel\n",
    "show_plots(\"SVM with Linear Kernel\", svm_linear_results, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radial basis function kernel\n",
    "show_plots(\"SVM with RBF Kernel\", svm_rbf_results, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial kernel\n",
    "show_plots(\"SVM with Polynomial Kernel\", svm_poly_results, X_test, y_test)"
   ]
  },
  {
   "source": [
    "# Neural Networks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Step 1: Run Neural Networks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_results = []\n",
    "tanh_results = []\n",
    "logi_results = []\n",
    "\n",
    "activations = ['relu', 'tanh', 'logsitic']\n",
    "iters = 10000 # sklearn's MLPClassifier halts further iterations after the training converges\n",
    "layers = [(22), (22, 22), (22, 22, 22), (30)]\n",
    "alphas = [0.01, 0.001, 0.0001, 0.00001] # L2 penalty (regularization term) parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in layers:\n",
    "    for a in alphas:\n",
    "        print(\"layers: {0}, alpha: {1}\".format(l, a))\n",
    "        relu_results.append(sklearn_model(X_train, y_train, X_test, y_test, 2, 0, iters, hidden_layer_sizes=l, activation='relu', alpha=a))\n",
    "        tanh_results.append(sklearn_model(X_train, y_train, X_test, y_test, 2, 0, iters, hidden_layer_sizes=l, activation='tanh', alpha=a))\n",
    "        logi_results.append(sklearn_model(X_train, y_train, X_test, y_test, 2, 0, iters, hidden_layer_sizes=l, activation='logistic', alpha=a))"
   ]
  },
  {
   "source": [
    "### Step 2: Display data obtained from the neural networks run"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_results_to_dataframe(model_set):\n",
    "    training_acc = []\n",
    "    testing_acc = []\n",
    "    for model in model_set:\n",
    "        # grab accuracies for each model\n",
    "        training_acc.append(model[0][0][0])\n",
    "        testing_acc.append(model[0][1][0])\n",
    "\n",
    "    tr_dict, ts_dict = {}, {}\n",
    "    i = 0\n",
    "    for l in layers:\n",
    "        for a in alphas:\n",
    "            tr_dict[\"layers={0}, alpha={1}\".format(l, a)] = training_acc[i]\n",
    "            ts_dict[\"layers={0}, alpha={1}\".format(l, a)] = testing_acc[i]\n",
    "            i += 1\n",
    "\n",
    "    c_accs = {}\n",
    "    c_accs['Acc_tr'] = tr_dict\n",
    "    c_accs['Acc_ts'] = ts_dict\n",
    "\n",
    "    c_acc_df = pd.DataFrame(c_accs)\n",
    "    \n",
    "    prfs_lst = []\n",
    "    for model in model_set:\n",
    "        prfs_lst.append({k: model[1][0][k] for k in ('0.0', '1.0')})\n",
    "\n",
    "    return c_acc_df, prfs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['ReLU', 'tanh', 'Logisitic/Sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for model_set in (relu_results, tanh_results, logi_results):\n",
    "    print(\"\\n========== Neural Network with {} Activation ==========\".format(titles[i]))\n",
    "    c_acc, prfs_lst = nn_results_to_dataframe(model_set)\n",
    "    display(c_acc)\n",
    "\n",
    "    j = 0\n",
    "    for l in layers:\n",
    "        for a in alphas:\n",
    "            print(\"\\nlayers={0}, alpha={1}\".format(l, a))\n",
    "            prfs_df = pd.DataFrame(prfs_lst[j])\n",
    "            display(prfs_df)\n",
    "            j += 1\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "source": [
    "### Step 3: Gather data from the costs of each neural network\n",
    "\n",
    "sklearn's MLPClassifier has a loss curve attribute, which contains \"The ith element in the list represents the loss at the ith iteration.\" "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average costs for each neural network run\n",
    "avg_cost_relu = [np.average(r[2].loss_curve_) for r in relu_results]\n",
    "avg_cost_tanh = [np.average(r[2].loss_curve_) for r in tanh_results]\n",
    "avg_cost_logi = [np.average(r[2].loss_curve_) for r in logi_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for the legends of each model's plots\n",
    "labels = [\"H_L={0}, a={1}\".format(l, a) for l in layers for a in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_show_plots(title, model_set, avg_cost):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.subplots_adjust(wspace=1)\n",
    "    fig.suptitle(\"Neural Network: {} Activation\".format(title))\n",
    "\n",
    "    for i in range(len(model_set)):\n",
    "        plot_precision_recall_curve(model_set[i][2], X_test, y_test, ax=ax[0], name='{}'.format(labels[i]))\n",
    "    ax[0].set_title('Precision-Recall Curve')\n",
    "    ax[0].legend(bbox_to_anchor=(1, 1))\n",
    "\n",
    "    label_avg_cost = [\"{0}, Avg Cost: {1:2.2}\".format(labels[i], avg_cost[i]) for i in range(16)]\n",
    "    for result in model_set:\n",
    "        ax[1].plot(result[2].loss_curve_)\n",
    "        ax[1].legend(label_avg_cost, bbox_to_anchor=(2, 1))\n",
    "    ax[1].set_title(\"Loss Curves\")\n",
    "    ax[1].set_xlabel('Iterations')\n",
    "    ax[1].set_ylabel('Cost')"
   ]
  },
  {
   "source": [
    "### Step 4: Plot results and loss curves obtained from the neural networks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN with ReLU\n",
    "nn_show_plots(\"ReLU\", relu_results, avg_cost_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN with tanh\n",
    "nn_show_plots(\"tanh\", tanh_results, avg_cost_tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN with logistic (sigmoid)\n",
    "nn_show_plots(\"Logistic/Sigmoid\", logi_results, avg_cost_logi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0a868f5554589e2af52e9ac65f4e9cf67d07107fa900cd1827df20b8357fa2962",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "144fb71a79f9c612d06d7a9fcb439de36ddb2e1a62502bfc5dbf46a660d6c8ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}